<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://pannenetsf.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://pannenetsf.github.io//" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-13T01:14:06+00:00</updated><id>https://pannenetsf.github.io//feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How to manage my second brain? Notion/Obsidian/Zotero/TexMacs/LaTeX</title><link href="https://pannenetsf.github.io//blog/2024/content/" rel="alternate" type="text/html" title="How to manage my second brain? Notion/Obsidian/Zotero/TexMacs/LaTeX"/><published>2024-03-08T00:00:00+00:00</published><updated>2024-03-08T00:00:00+00:00</updated><id>https://pannenetsf.github.io//blog/2024/content</id><content type="html" xml:base="https://pannenetsf.github.io//blog/2024/content/"><![CDATA[<p>TBD</p>]]></content><author><name></name></author><category term="productivity"/><summary type="html"><![CDATA[TBD]]></summary></entry><entry><title type="html">NeoVim和fbterm总结：没有GUI和ssh怎么写代码</title><link href="https://pannenetsf.github.io//blog/2023/vimfbterm-copy/" rel="alternate" type="text/html" title="NeoVim和fbterm总结：没有GUI和ssh怎么写代码"/><published>2023-10-08T00:00:00+00:00</published><updated>2023-10-08T00:00:00+00:00</updated><id>https://pannenetsf.github.io//blog/2023/vimfbterm%20copy</id><content type="html" xml:base="https://pannenetsf.github.io//blog/2023/vimfbterm-copy/"><![CDATA[<h2 id="前因后果">前因后果</h2> <p>小长假期间跳板机的ssh转发功能挂掉了，vscode-remote没办法再用了，但是还有几个程序要调，所以就把NeoVim正经配成了一个IDE。某天又看到自己尘封已久的小破笔记本，竟然还能打开，只是开着图形界面续航实在不忍直视，所以尝试了一下通过fbterm在tty窗口直接开发。</p> <h2 id="neovim">NeoVim</h2> <p>之前主要在用VsCode，快捷键也是Vim的那一套，所以这次的目的是把除了编辑之外的功能捡起来，比如补全，比如调试，比如文件浏览，比如控制台，基本上就是把NeoVim打造成一个用得惯的VSC。</p> <p>我用的预配置是[1]<a href="https://www.lunarvim.org/">LunarVim</a>，一些常用的功能已经通过相对丰富的插件支持。LSP的支持带来了不错的补全以及高亮，写码体验尚佳；Copilot的支持也几乎和VSC一致，省去写很多胶水的功夫。 主要的问题在于调试，lvim只预装了DAP，很灵活，但是配置也相对麻烦一点，所以我转向了配置以及调试更傻瓜的[2]<a href="https://github.com/puremourning/vimspector">Vimspector</a>。它的调试和VSC一样，都是基于debugpy，连配置文件都长得很像：</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">➜</span><span class="w">  </span><span class="err">pllm</span><span class="w"> </span><span class="err">git:(master)</span><span class="w"> </span><span class="err">✗</span><span class="w"> </span><span class="err">cat</span><span class="w"> </span><span class="err">.vimspector.json</span><span class="w">
</span><span class="err">//</span><span class="w"> </span><span class="err">.vimspector.json</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="nl">"configurations"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"run"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"adapter"</span><span class="p">:</span><span class="w"> </span><span class="s2">"debugpy"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"default"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
      </span><span class="nl">"configuration"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"request"</span><span class="p">:</span><span class="w"> </span><span class="s2">"launch"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"python"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"cwd"</span><span class="p">:</span><span class="w"> </span><span class="s2">"${workspaceRoot}"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"stopOnEntry"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
        </span><span class="nl">"program"</span><span class="p">:</span><span class="w"> </span><span class="s2">"${file}"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"justMyCode"</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w">
        </span><span class="nl">"env"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nl">"PYTHONPATH"</span><span class="p">:</span><span class="w"> </span><span class="s2">"${workspaceRoot}"</span><span class="p">,</span><span class="w">
          </span><span class="nl">"XXX_LOG_LEVEL"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DEBUG"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="nl">"args"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
          </span><span class="s2">"--config"</span><span class="p">,</span><span class="w">
          </span><span class="s2">"xxx.yaml"</span><span class="p">,</span><span class="w">
        </span><span class="p">]</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="nl">"breakpoints"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"exception"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nl">"raised"</span><span class="p">:</span><span class="w"> </span><span class="s2">"N"</span><span class="p">,</span><span class="w">
          </span><span class="nl">"uncaught"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
          </span><span class="nl">"userUnhandled"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="w">
        </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>在快捷键上也可以直接将快捷键风格设置成VSC，保证一致的体验。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim.g.vimspector_enable_mappings = 'VISUAL_STUDIO'
</code></pre></div></div> <h2 id="fbterm">FBTerm</h2> <p>FBTerm是单纯想体验一下纯TUI写代码的感觉，让陪了我四年的电脑继续发光发热。TTY不能原生显示中文的原因是UTF8的编码位宽是和ASICI不一样的，在默认的显示上会出问题。有了FBterm以及带有中文字形的字体（比如FiraCode、文泉驿），tty也可以正常显示中文。如果想要在FBTerm同时输入中文呢，可以参考这篇博客 [3]<a href="https://jia.je/misc/2018/07/12/using-fcitx-fbterm/">杰哥的小笔记</a>，需要注意的是fcitx相关的包最好替换成fcitx5。</p>]]></content><author><name></name></author><category term="productivity"/><summary type="html"><![CDATA[前因后果]]></summary></entry><entry><title type="html">新的开始</title><link href="https://pannenetsf.github.io//blog/2023/NewStart/" rel="alternate" type="text/html" title="新的开始"/><published>2023-09-10T00:00:00+00:00</published><updated>2023-09-10T00:00:00+00:00</updated><id>https://pannenetsf.github.io//blog/2023/NewStart</id><content type="html" xml:base="https://pannenetsf.github.io//blog/2023/NewStart/"><![CDATA[<p>第二次的第一篇博客，一个新的开始欸！</p> <div id="comments"></div>]]></content><author><name></name></author><category term="daily"/><summary type="html"><![CDATA[第二次的第一篇博客，一个新的开始欸！]]></summary></entry><entry><title type="html">MoE training profile</title><link href="https://pannenetsf.github.io//blog/2023/moe/" rel="alternate" type="text/html" title="MoE training profile"/><published>2023-04-09T00:00:00+00:00</published><updated>2023-04-09T00:00:00+00:00</updated><id>https://pannenetsf.github.io//blog/2023/moe</id><content type="html" xml:base="https://pannenetsf.github.io//blog/2023/moe/"><![CDATA[<p>最近传言Chat GPT也是MoE，想起之前做profile的经历，记录一下。</p> <p>MoE稀疏地被激活特定的线性层，并且需要分别对不同的worker scatter，计算完成后再gather，需要两次同步。虽然FC只是非常小的计算量，在MoE的体量下可以忽略负载不均衡的问题，但是两次同步之间的计算量较大，当整个通信组的变大的时候，不同rank之间的速度极差也有概率变大，在64/128卡的时候几乎可以闲置接近一半。</p> <p>如果想让这个overhead减小，我能想到的方案有这几个：</p> <ol> <li>将整个训练的group切分成多个，每个subgroup分别进行route，之后定期同步不同的subgroup。（有点像联邦学习）问题是每个subgroup的batch size都被限制住了，这样会不会造成不稳定的情况？从之前简单摸FL的经历来看，检测、分类模型都会有退化现象。</li> <li>能不能通信的时候算一些别的有意义的事情？比如将experts设置成一个分支，通信的时候把另外的不需要通信的分支算完，差不多之后通信也都完成了。</li> <li>把现在torch的if/else代码改到cuda上</li> </ol> <p>后两者都只能减少最少的overhead，而第一个又会带来精度问题，好奇OpenAI是怎么scale到数千个worker的。</p>]]></content><author><name></name></author><category term="productivity"/><summary type="html"><![CDATA[最近传言Chat GPT也是MoE，想起之前做profile的经历，记录一下。]]></summary></entry><entry><title type="html">How to properly profile GPU applications</title><link href="https://pannenetsf.github.io//blog/2023/gpu-prof/" rel="alternate" type="text/html" title="How to properly profile GPU applications"/><published>2023-04-03T00:00:00+00:00</published><updated>2023-04-03T00:00:00+00:00</updated><id>https://pannenetsf.github.io//blog/2023/gpu-prof</id><content type="html" xml:base="https://pannenetsf.github.io//blog/2023/gpu-prof/"><![CDATA[<h2 id="why-not-nvidia-smi">Why not <code class="language-plaintext highlighter-rouge">nvidia-smi</code></h2> <p>According to the documents, the utilization filed in the SMI output just reflects <strong>the fraction time</strong> of GPU being used, but not <strong>how much of GPU power</strong> being used. Knowing the fraction of used time is important when we are to remove the unnecessary CPU usage at the initial stage of some project, so that the app would not be blocked by CPU.</p> <p>But when most of job is done by GPU, we need to profile the output power of the GPU and determine which part is the bottleneck.</p> <h2 id="find-the-slow-stage-with-nsys">Find the slow stage with <code class="language-plaintext highlighter-rouge">nsys</code></h2> <p>Nsight system can be used to get the general sequence chart of <code class="language-plaintext highlighter-rouge">CUDA API</code>, <code class="language-plaintext highlighter-rouge">Kernel invoking</code>, and <code class="language-plaintext highlighter-rouge">NVTX Tags</code>.</p> <ol> <li>Tag different stages of the application with <code class="language-plaintext highlighter-rouge">NVTX</code>. <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pytorch
</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">nvtx</span><span class="p">.</span><span class="nf">range_push</span><span class="p">(</span><span class="n">tag_name</span><span class="p">)</span>
<span class="c1"># code of the stage
</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">nvtx</span><span class="p">.</span><span class="nf">range_pop</span><span class="p">()</span>
<span class="c1"># or you can warp them with a context manager
</span></code></pre></div> </div> </li> <li>Remove the stages that you do not want to profile, like preparation and finalization. <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">cudart</span><span class="p">().</span><span class="nf">cudaProfilerStart</span><span class="p">()</span>
<span class="c1"># the code that you want to profile
</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">cudart</span><span class="p">().</span><span class="nf">cudaProfilerStop</span><span class="p">()</span>
</code></pre></div> </div> </li> <li>Profile the code with <code class="language-plaintext highlighter-rouge">nsys</code> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nsys profile <span class="nt">--gpu-metrics-device</span><span class="o">=</span>0,1 <span class="se">\</span>
<span class="nt">--capture-range</span><span class="o">=</span>cudaProfilerApi <span class="se">\</span>
<span class="nt">--stop-on-range-end</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">-w</span> <span class="nb">true</span> <span class="se">\</span>
<span class="nt">-t</span> cuda,nvtx <span class="se">\</span>
<span class="nt">-o</span> report%p <span class="se">\</span>
<span class="nt">-f</span> <span class="nb">true</span> <span class="se">\</span>
your_program <span class="se">\</span>
your_args 
</code></pre></div> </div> <p>If you use MPI, the <code class="language-plaintext highlighter-rouge">%p</code> would show the rank of the report.</p> </li> </ol> <p>Refer to <a href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#gpu-metric-sampling">Metric</a> for explanation. Some important metrics are:</p> <ol> <li>GR Active</li> <li>Compute Warps in Flight</li> <li>Active SM Unused Warp Slots</li> <li>Idle SM Unused Warp Slots</li> <li>SM Active</li> <li>SM Issue</li> <li>Tensor Active</li> <li>DRAM Bandwidth</li> </ol>]]></content><author><name></name></author><category term="productivity"/><summary type="html"><![CDATA[Why not nvidia-smi]]></summary></entry></feed>